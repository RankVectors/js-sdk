/* tslint:disable */
/* eslint-disable */
/**
 * RankVectors API
 * Intelligent internal linking optimization API using AI.   RankVectors helps you automatically discover and implement optimal internal links  across your website to improve SEO performance and user experience.  ## Key Features - **AI-Powered Analysis**: Uses OpenAI embeddings to find optimal linking opportunities - **Smart Crawling**: Automatically crawls and analyzes your website content - **Automated Implementation**: Implement links via webhooks or manual instructions - **Credit-Based System**: Pay-per-use model with transparent pricing - **Multi-Platform Support**: Works with any CMS or platform via REST API  ## Getting Started 1. Create a project with your website URL 2. Start a crawl to analyze your content 3. Generate AI-powered link suggestions 4. Implement suggestions via API or webhook 5. Track performance and manage credits  ## Authentication All API endpoints require authentication using your RankVectors API key. Include your API key in the `Authorization` header: ``` Authorization: Bearer YOUR_API_KEY ```  Get your API key from your RankVectors dashboard: Settings â†’ API Keys 
 *
 * The version of the OpenAPI document: 1.2.0
 * Contact: support@rankvectors.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


import * as runtime from '../runtime';
import type {
  Crawl,
  StartCrawlRequest,
} from '../models/index';
import {
    CrawlFromJSON,
    CrawlToJSON,
    StartCrawlRequestFromJSON,
    StartCrawlRequestToJSON,
} from '../models/index';

export interface GetCrawlHistoryRequest {
    projectId: string;
}

export interface StartCrawlOperationRequest {
    projectId: string;
    startCrawlRequest?: StartCrawlRequest;
}

/**
 * 
 */
export class CrawlingApi extends runtime.BaseAPI {

    /**
     * Get the crawl history for a project
     * Get crawl history
     */
    async getCrawlHistoryRaw(requestParameters: GetCrawlHistoryRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<Crawl>>> {
        if (requestParameters['projectId'] == null) {
            throw new runtime.RequiredError(
                'projectId',
                'Required parameter "projectId" was null or undefined when calling getCrawlHistory().'
            );
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        if (this.configuration && this.configuration.apiKey) {
            headerParameters["Authorization"] = await this.configuration.apiKey("Authorization"); // ApiKeyAuth authentication
        }


        let urlPath = `/api/projects/{projectId}/crawl`;
        urlPath = urlPath.replace(`{${"projectId"}}`, encodeURIComponent(String(requestParameters['projectId'])));

        const response = await this.request({
            path: urlPath,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(CrawlFromJSON));
    }

    /**
     * Get the crawl history for a project
     * Get crawl history
     */
    async getCrawlHistory(requestParameters: GetCrawlHistoryRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<Crawl>> {
        const response = await this.getCrawlHistoryRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * Start crawling a website to analyze content for link opportunities
     * Start website crawl
     */
    async startCrawlRaw(requestParameters: StartCrawlOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Crawl>> {
        if (requestParameters['projectId'] == null) {
            throw new runtime.RequiredError(
                'projectId',
                'Required parameter "projectId" was null or undefined when calling startCrawl().'
            );
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        if (this.configuration && this.configuration.apiKey) {
            headerParameters["Authorization"] = await this.configuration.apiKey("Authorization"); // ApiKeyAuth authentication
        }


        let urlPath = `/api/projects/{projectId}/crawl`;
        urlPath = urlPath.replace(`{${"projectId"}}`, encodeURIComponent(String(requestParameters['projectId'])));

        const response = await this.request({
            path: urlPath,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: StartCrawlRequestToJSON(requestParameters['startCrawlRequest']),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => CrawlFromJSON(jsonValue));
    }

    /**
     * Start crawling a website to analyze content for link opportunities
     * Start website crawl
     */
    async startCrawl(requestParameters: StartCrawlOperationRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Crawl> {
        const response = await this.startCrawlRaw(requestParameters, initOverrides);
        return await response.value();
    }

}
